tosca_definitions_version: cloudify_dsl_1_3

description: >
  This Blueprint installs the simple Kubernetes cluster on an Azure Cloud environment.

imports:
  - http://www.getcloudify.org/spec/cloudify/4.0/types.yaml
  - https://raw.githubusercontent.com/cloudify-cosmo/cloudify-azure-plugin/1.4.2/plugin.yaml
  - http://www.getcloudify.org/spec/fabric-plugin/1.3.1/plugin.yaml
  - http://www.getcloudify.org/spec/diamond-plugin/1.3.5/plugin.yaml
  - types/scale.yaml
#  - imports/kubernetes-blueprint.yaml # We use Azure Extensions to install Docker

inputs:

  resource_prefix:
    default: k8s

  resource_suffix:
    default: '1'

  # Azure account information

  location:
    type: string
    required: true
    default: eastus

  retry_after:
    type: integer
    default: 60

  # Existing manager resources
  mgr_resource_group_name:
    type: string
    required: true

  mgr_virtual_network_name:
    type: string
    required: true

  mgr_subnet_name:
    type: string
    required: true

  # Virtual Machine information

  vm_size:
    type: string
    required: true
    default: Standard_A0

  vm_os_family:
    type: string
    required: true
    default: linux

  vm_image_publisher:
    type: string
    required: true
    default: Canonical

  vm_image_offer:
    type: string
    required: true
    default: UbuntuServer

  vm_image_sku:
    type: string
    required: true
    default: 14.04.4-LTS

  vm_image_version:
    type: string
    required: true
    default: 14.04.201604060

  agent_user:
    description: >
      Username to create as the VM's administrator user
    type: string
    required: true
    default: cloudify

  vm_os_password:
    description: >
      Password to use for the VM's administrator user
    type: string
    required: true
    default: Cl0ud1fy!

  agent_user_public_key_data:
    default: ssh-rsa AAAAA3----your-key-here----aabbzz

  vm_os_pubkeys:
    description: the public key
    default:
    - path: {concat:[ '/home/', { get_input: agent_user }, '/.ssh/authorized_keys' ]}
      keyData: { get_input: agent_user_public_key_data }

  vm_os_pubkey_auth_only:
    default: true

  # Application information

  webserver_port:
    description: The external web server port
    default: 8080

  private_key_path:
    description: >
      This is the private key that matches the public key in input agent_user_public_key_data.
    default: /home/cloudify/.ssh/id_rsa

  agent_config:
    default:
      user: { get_input: agent_user }
      key: { get_input: private_key_path }
      install_method: remote
      min_workers: 2

dsl_definitions:

  azure_config: &azure_config
    subscription_id: { get_secret: subscription_id }
    tenant_id: { get_secret: tenant_id }
    client_id: { get_secret: client_id }
    client_secret: { get_secret: client_secret }

node_templates:

  kubernetes_master:
    type: cloudify.nodes.SoftwareComponent
    interfaces:
      cloudify.interfaces.lifecycle:
        start:
          implementation: fabric.fabric_plugin.tasks.run_commands
          inputs:
            fabric_env:
              host_string: { get_attribute: [ kubernetes_master_host, ip ] }
              user: { get_input: agent_user }
              key_filename: { get_input: private_key_path }
            commands:
              - "curl -LO https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectl"
              - "chmod +x kubectl"
              - "rm -rf kube-deploy"
              - "curl -L https://github.com/kubernetes/kube-deploy/archive/master.tar.gz | tar xz && cd kube-deploy-master/docker-multinode;sudo ./master.sh"
    relationships:
      - type: cloudify.relationships.depends_on
        target: kubernetes_master_docker
      - type: cloudify.relationships.contained_in
        target: kubernetes_master_host

  kubernetes_node:
    type: cloudify.nodes.SoftwareComponent
    interfaces:
      cloudify.interfaces.lifecycle:
        start:
          implementation: fabric.fabric_plugin.tasks.run_commands
          inputs:
            fabric_env:
              host_string: { get_attribute: [ kubernetes_node_host, ip ] }
              user: { get_input: agent_user }
              key_filename: { get_input: private_key_path }
            commands:
              - "rm -rf kube-deploy"
              - { concat: [ "curl -L https://github.com/kubernetes/kube-deploy/archive/master.tar.gz | tar xz && cd kube-deploy-master/docker-multinode;sudo MASTER_IP=", { get_attribute: [ kubernetes_master_host, ip ] }," ./worker.sh" ] }
    relationships:
      - type: cloudify.relationships.depends_on
        target: kubernetes_master
      - type: cloudify.relationships.contained_in
        target: kubernetes_node_host

  kubectl:
    # For convenience, we install the kubectl on your master.
    type: cloudify.nodes.Root
    interfaces:
      cloudify.interfaces.lifecycle:
        create:
          implementation: scripts/kubectl.py
          inputs:
            kubectl_url: 'http://storage.googleapis.com/kubernetes-release/release/v1.0.1/bin/linux/amd64/kubectl'
    relationships:
      - type: cloudify.relationships.contained_in
        target: kubernetes_master_host

  kubernetes_master_docker:
    type: cloudify.azure.nodes.compute.VirtualMachineExtension
    properties:
      location: { get_input: location }
      retry_after: { get_input: retry_after }
      azure_config: *azure_config
    interfaces:
      cloudify.interfaces.lifecycle:
        create:
          inputs:
            resource_config:
              publisher: Microsoft.Azure.Extensions
              type: DockerExtension
              typeHandlerVersion: '1.0'
              autoUpgradeMinorVersion: true
              settings: {}
              protectedSettings: {}
    relationships:
    - type: cloudify.azure.relationships.vmx_contained_in_vm
      target: kubernetes_master_host

  kubernetes_node_docker:
    type: cloudify.azure.nodes.compute.VirtualMachineExtension
    properties:
      location: { get_input: location }
      retry_after: { get_input: retry_after }
      azure_config: *azure_config
    interfaces:
      cloudify.interfaces.lifecycle:
        create:
          inputs:
            resource_config:
              publisher: Microsoft.Azure.Extensions
              type: DockerExtension
              typeHandlerVersion: '1.0'
              autoUpgradeMinorVersion: true
              settings: {}
              protectedSettings: {}
    relationships:
    - type: cloudify.azure.relationships.vmx_contained_in_vm
      target: kubernetes_node_host

  kubernetes_master_host:
    type: cloudify.azure.nodes.compute.VirtualMachine
    properties:
      azure_config: *azure_config
      location: { get_input: location }
      retry_after: { get_input: retry_after }
      os_family: { get_input: vm_os_family }
      resource_config:
        hardwareProfile:
          vmSize: { get_input: vm_size }
        storageProfile:
          imageReference:
            publisher: { get_input: vm_image_publisher }
            offer: { get_input: vm_image_offer }
            sku: { get_input: vm_image_sku }
            version: { get_input: vm_image_version }
        osProfile:
          adminUsername: { get_input: agent_user }
          adminPassword: { get_input: vm_os_password }
          linuxConfiguration:
            ssh:
              publicKeys: { get_input: vm_os_pubkeys }
            disablePasswordAuthentication: { get_input: vm_os_pubkey_auth_only }
      agent_config: { get_input: agent_config }
    relationships:
    - type: cloudify.azure.relationships.contained_in_resource_group
      target: resource_group
    - type: cloudify.azure.relationships.connected_to_storage_account
      target: storage_account
    - type: cloudify.azure.relationships.connected_to_availability_set
      target: availability_set
    - type: cloudify.azure.relationships.connected_to_nic
      target: kubernetes_master_host_nic

  kubernetes_node_host:
    type: cloudify.azure.nodes.compute.VirtualMachine
    properties:
      azure_config: *azure_config
      location: { get_input: location }
      retry_after: { get_input: retry_after }
      os_family: { get_input: vm_os_family }
      resource_config:
        hardwareProfile:
          vmSize: { get_input: vm_size }
        storageProfile:
          imageReference:
            publisher: { get_input: vm_image_publisher }
            offer: { get_input: vm_image_offer }
            sku: { get_input: vm_image_sku }
            version: { get_input: vm_image_version }
        osProfile:
          adminUsername: { get_input: agent_user }
          adminPassword: { get_input: vm_os_password }
          linuxConfiguration:
            ssh:
              publicKeys: { get_input: vm_os_pubkeys }
            disablePasswordAuthentication: { get_input: vm_os_pubkey_auth_only }
      agent_config: { get_input: agent_config }
    relationships:
    - type: cloudify.azure.relationships.contained_in_resource_group
      target: resource_group
    - type: cloudify.azure.relationships.connected_to_storage_account
      target: storage_account
    - type: cloudify.azure.relationships.connected_to_availability_set
      target: availability_set
    - type: cloudify.azure.relationships.connected_to_nic
      target: kubernetes_node_host_nic
    interfaces:
      cloudify.interfaces.monitoring_agent:
        install:
          implementation: diamond.diamond_agent.tasks.install
          inputs:
            diamond_config:
              interval: 1
        start: diamond.diamond_agent.tasks.start
        stop: diamond.diamond_agent.tasks.stop
        uninstall: diamond.diamond_agent.tasks.uninstall
      cloudify.interfaces.monitoring:
        start:
          implementation: diamond.diamond_agent.tasks.add_collectors
          inputs:
            collectors_config:
              ProcessResourcesCollector:
                config:
                  enabled: true
                  unit: B
                  measure_collector_time: true
                  cpu_interval: 0.5
                  process:
                    hyperkube:
                      name: hyperkube

  resource_group:
    type: cloudify.azure.nodes.ResourceGroup
    properties:
      name: {concat:[{get_input: resource_prefix},arg,{get_input: resource_suffix}]}
      location: { get_input: location }
      azure_config: *azure_config

  storage_account:
    type: cloudify.azure.nodes.storage.StorageAccount
    properties:
      location: { get_input: location }
      azure_config: *azure_config
      retry_after: { get_input: retry_after }
      resource_config:
        accountType: Standard_LRS
    relationships:
    - type: cloudify.azure.relationships.contained_in_resource_group
      target: resource_group

  virtual_network:
    type: cloudify.azure.nodes.network.VirtualNetwork
    properties:
      resource_group_name: { get_input: mgr_resource_group_name }
      name: { get_input: mgr_virtual_network_name }
      azure_config: *azure_config
      use_external_resource: true
      location: { get_input: location }
    relationships:
    - type: cloudify.azure.relationships.contained_in_resource_group
      target: resource_group

  subnet:
    type: cloudify.azure.nodes.network.Subnet
    properties:
      resource_group_name: { get_input: mgr_resource_group_name }
      name: { get_input: mgr_subnet_name }
      azure_config: *azure_config
      use_external_resource: true
      location: { get_input: location }
    relationships:
    - type: cloudify.azure.relationships.contained_in_virtual_network
      target: virtual_network

  network_security_group:
    type: cloudify.azure.nodes.network.NetworkSecurityGroup
    properties:
      name: {concat:[{get_input: resource_prefix},nsg,{get_input: resource_suffix}]}
      location: { get_input: location }
      azure_config: *azure_config
      retry_after: { get_input: retry_after }
      resource_config:
        securityRules:
        - name: {concat:[{get_input: resource_prefix},nsg,{get_input: resource_suffix},ssh]}
          properties:
            description: SSH access
            protocol: Tcp
            sourcePortRange: '*'
            destinationPortRange: 22
            sourceAddressPrefix: '*'
            destinationAddressPrefix: '*'
            priority: 102
            access: Allow
            direction: Inbound
        - name: {concat:[{get_input: resource_prefix},nsg,{get_input: resource_suffix},udp]}
          properties:
            description: 53 UDP access
            protocol: Udp
            sourcePortRange: '*'
            destinationPortRange: 53
            sourceAddressPrefix: '*'
            destinationAddressPrefix: '*'
            priority: 103
            access: Allow
            direction: Inbound
        - name: {concat:[{get_input: resource_prefix},nsg,{get_input: resource_suffix},tcp53]}
          properties:
            description: 53 TCP access
            protocol: Tcp
            sourcePortRange: '*'
            destinationPortRange: 53
            sourceAddressPrefix: '*'
            destinationAddressPrefix: '*'
            priority: 104
            access: Allow
            direction: Inbound
        - name: {concat:[{get_input: resource_prefix},nsg,{get_input: resource_suffix},http]}
          properties:
            description: HTTP access
            protocol: Tcp
            sourcePortRange: '*'
            destinationPortRange: 80
            sourceAddressPrefix: '*'
            destinationAddressPrefix: '*'
            priority: 105
            access: Allow
            direction: Inbound
        - name: {concat:[{get_input: resource_prefix},nsg,{get_input: resource_suffix},https]}
          properties:
            description: HTTPS access
            protocol: Tcp
            sourcePortRange: '*'
            destinationPortRange: 443
            sourceAddressPrefix: '*'
            destinationAddressPrefix: '*'
            priority: 106
            access: Allow
            direction: Inbound
        - name: {concat:[{get_input: resource_prefix},nsg,{get_input: resource_suffix},2379tcp]}
          properties:
            description: 2379 TCP access
            protocol: Tcp
            sourcePortRange: '*'
            destinationPortRange: 2379
            sourceAddressPrefix: '*'
            destinationAddressPrefix: '*'
            priority: 107
            access: Allow
            direction: Inbound
        - name: {concat:[{get_input: resource_prefix},nsg,{get_input: resource_suffix},4001tcp]}
          properties:
            description: 4001 TCP access
            protocol: Tcp
            sourcePortRange: '*'
            destinationPortRange: 4001
            sourceAddressPrefix: '*'
            destinationAddressPrefix: '*'
            priority: 108
            access: Allow
            direction: Inbound
        - name: {concat:[{get_input: resource_prefix},nsg,{get_input: resource_suffix},6443tcp]}
          properties:
            description: 6443 TCP access
            protocol: Tcp
            sourcePortRange: '*'
            destinationPortRange: 6443
            sourceAddressPrefix: '*'
            destinationAddressPrefix: '*'
            priority: 109
            access: Allow
            direction: Inbound
        - name: {concat:[{get_input: resource_prefix},nsg,{get_input: resource_suffix},8000tcp]}
          properties:
            description: 8000 TCP access
            protocol: Tcp
            sourcePortRange: '*'
            destinationPortRange: 8000
            sourceAddressPrefix: '*'
            destinationAddressPrefix: '*'
            priority: 110
            access: Allow
            direction: Inbound
        - name: {concat:[{get_input: resource_prefix},nsg,{get_input: resource_suffix},http8080]}
          properties:
            description: 8080 TCP access
            protocol: Tcp
            sourcePortRange: '*'
            destinationPortRange: 8080
            sourceAddressPrefix: '*'
            destinationAddressPrefix: '*'
            priority: 111
            access: Allow
            direction: Inbound
        - name: {concat:[{get_input: resource_prefix},nsg,{get_input: resource_suffix},9090tcp]}
          properties:
            description: 9090 TCP access
            protocol: Tcp
            sourcePortRange: '*'
            destinationPortRange: 9090
            sourceAddressPrefix: '*'
            destinationAddressPrefix: '*'
            priority: 112
            access: Allow
            direction: Inbound
        - name: {concat:[{get_input: resource_prefix},nsg,{get_input: resource_suffix},10250tcp]}
          properties:
            description: 10250 TCP access
            protocol: Tcp
            sourcePortRange: '*'
            destinationPortRange: 10250
            sourceAddressPrefix: '*'
            destinationAddressPrefix: '*'
            priority: 113
            access: Allow
            direction: Inbound
    relationships:
    - type: cloudify.azure.relationships.contained_in_resource_group
      target: resource_group

  availability_set:
    type: cloudify.azure.nodes.compute.AvailabilitySet
    properties:
      name: {concat:[{get_input: resource_prefix},availset,{get_input: resource_suffix}]}
      location: { get_input: location }
      azure_config: *azure_config
      retry_after: { get_input: retry_after }
    relationships:
    - type: cloudify.azure.relationships.contained_in_resource_group
      target: resource_group

  kubernetes_node_host_nic:
    type: cloudify.azure.nodes.network.NetworkInterfaceCard
    properties:
      location: { get_input: location }
      azure_config: *azure_config
      retry_after: { get_input: retry_after }
    relationships:
    - type: cloudify.azure.relationships.contained_in_resource_group
      target: resource_group
    - type: cloudify.azure.relationships.nic_connected_to_network_security_group
      target: network_security_group
    - type: cloudify.azure.relationships.nic_connected_to_ip_configuration
      target: kubernetes_node_host_nic_ip_cfg

  kubernetes_master_host_nic:
    type: cloudify.azure.nodes.network.NetworkInterfaceCard
    properties:
      location: { get_input: location }
      azure_config: *azure_config
      retry_after: { get_input: retry_after }
    relationships:
    - type: cloudify.azure.relationships.contained_in_resource_group
      target: resource_group
    - type: cloudify.azure.relationships.nic_connected_to_network_security_group
      target: network_security_group
    - type: cloudify.azure.relationships.nic_connected_to_ip_configuration
      target: kubernetes_master_host_nic_ip_cfg

  kubernetes_node_host_nic_ip_cfg:
    type: cloudify.azure.nodes.network.IPConfiguration
    properties:
      location: { get_input: location }
      azure_config: *azure_config
      retry_after: { get_input: retry_after }
      resource_config:
        privateIPAllocationMethod: Dynamic
    relationships:
    - type: cloudify.azure.relationships.contained_in_resource_group
      target: resource_group
    - type: cloudify.azure.relationships.ip_configuration_connected_to_subnet
      target: subnet

  kubernetes_master_host_nic_ip_cfg:
    type: cloudify.azure.nodes.network.IPConfiguration
    properties:
      location: { get_input: location }
      azure_config: *azure_config
      retry_after: { get_input: retry_after }
      resource_config:
        privateIPAllocationMethod: Dynamic
    relationships:
    - type: cloudify.azure.relationships.ip_configuration_connected_to_subnet
      target: subnet
    - type: cloudify.azure.relationships.ip_configuration_connected_to_public_ip
      target: kubernetes_master_ip

  kubernetes_master_ip:
    type: cloudify.azure.nodes.network.PublicIPAddress
    properties:
      location: { get_input: location }
      azure_config: *azure_config
      retry_after: { get_input: retry_after }
      resource_config:
        publicIPAllocationMethod: Static
    relationships:
    - type: cloudify.azure.relationships.contained_in_resource_group
      target: resource_group

###########################################################
# This outputs section exposes the application endpoint.
# You can access it by running:
#   - cfy deployments -d <deployment_id> outputs
###########################################################

groups:

  azure_k8s_node_scale_group:
    members:
      - kubernetes_node_host_nic_ip_cfg
      - kubernetes_node_host_nic
      - kubernetes_node_host

  scale_up_group:
    members: [kubernetes_node_host]
    # This defines a scale group whose members may be scaled up, incrementing by 1.
    # The scale worflow is called when the following criteria are met
    # The Hyperkube process total CPU will be more than 3 for a total of 10 seconds.
    # No more than 6 hosts will be allowed.
    policies:
      auto_scale_up:
        type: scale_policy_type
        properties:
          policy_operates_on_group: true
          scale_limit: 6
          scale_direction: '<'
          scale_threshold: 30
          #service_selector: .*kubernetes_node_host.*.cpu.total.user
          service_selector: .*kubernetes_node_host.*cpu.total.user
          cooldown_time: 60
        triggers:
          execute_scale_workflow:
            type: cloudify.policies.triggers.execute_workflow
            parameters:
              workflow: scale
              workflow_parameters:
                delta: 1
                scalable_entity_name: kubernetes_node
                scale_compute: true

  scale_down_group:
  # This defines a scale group whose members may be scaled down. Only one host will be removed per run.
  # The scale worflow is called when the following criteria are met
  # The Hyperkube process total CPU will be less than 1 for a total of 200 seconds.
  # No less than 2 hosts will be allowed.
    members: [kubernetes_node_host]
    policies:
      auto_scale_down:
        type: scale_policy_type
        properties:
          scale_limit: 2
          scale_direction: '>'
          scale_threshold: 25
          #service_selector: .*kubernetes_node_host.*.process.hyperkube.cpu.percent
          service_selector: .*kubernetes_node_host.*cpu.total.user
          cooldown_time: 60
          moving_window_size: 30
        triggers:
          execute_scale_workflow:
           type: cloudify.policies.triggers.execute_workflow
           parameters:
             workflow: scale
             workflow_parameters:
               delta: -1
               scalable_entity_name: kubernetes_node
               scale_compute: true

  heal_group:
  # This defines a group of hosts in members that may be healed.
  # The heal workflow is called when a the following policy criteria are met.
  # Either the hyperkube process on the host, or the total host CPU need fall silent.
  # The host and all software that it is supposed to have running on it will be healed.
    members: [kubernetes_node_host]
    policies:
      simple_autoheal_policy:
        type: cloudify.policies.types.host_failure
        properties:
          service:
            - .*kubernetes_node_host.*.cpu.total.system
            - .*kubernetes_node_host.*.process.hyperkube.cpu.percent
          interval_between_workflows: 60
        triggers:
          auto_heal_trigger:
            type: cloudify.policies.triggers.execute_workflow
            parameters:
              workflow: heal
              workflow_parameters:
                node_instance_id: { 'get_property': [ SELF, node_id ] }
                diagnose_value: { 'get_property': [ SELF, diagnose ] }

policies:

  kubernetes_node_vms_scaling_policy:
    type: cloudify.policies.scaling
    properties:
      default_instances:  1
    targets: [azure_k8s_node_scale_group]

outputs:
  kubernetes_info:
    description: Kubernetes Dashboard URL
    value:
      url: { concat: ["http://", { get_attribute: [ kubernetes_master_host, public_ip ] } , ":8080/api/v1/proxy/namespaces/kube-system/services/kubernetes-dashboard" ] }
