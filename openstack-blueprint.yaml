###########################################################
# This Blueprint installs Kubernetes on Openstack
###########################################################

tosca_definitions_version: cloudify_dsl_1_3

description: >
  This blueprint creates a Kubernetes Cluster.
  It includes a master and two or more nodes with auto-scaling and auto-healing of the nodes.
  It is based on the Kubernetes Portable Multi-Node Cluster guide in the Kubernetes documentation website.
  https://kubernetes.io/docs/getting-started-guides/docker-multinode/

imports:
  - http://www.getcloudify.org/spec/cloudify/4.0/types.yaml
  - http://www.getcloudify.org/spec/openstack-plugin/2.0/plugin.yaml
  - http://www.getcloudify.org/spec/fabric-plugin/1.3.1/plugin.yaml
  - http://www.getcloudify.org/spec/diamond-plugin/1.3.5/plugin.yaml
  - types/scale.yaml

inputs:

  image:
    description: >
      A Ubuntu 14.04 image with Docker 11 preinstalled, along with the usual
      Cloudify agent requirements of passwordless ssh, passwordless sudo, and
      passwordless sudo over ssh configured

  flavor:
    description: >
      A machine type with more than 2 CPUs, 4096 GB RAM, and 8 GB of disk space.
      You might want to use 4 CPUs, 8192 MB RAM for the master.

  agent_user:
    description: >
      User for connecting to agent VM's
    default: ubuntu

  ssh_keyfile:
    default: /root/.ssh/agent_key.pem

dsl_definitions:

  hyperkube_monitoring: &hyperkube_monitoring
    collectors_config:
      CPUCollector: {}
      MemoryCollector: {}
      LoadAverageCollector: {}
      DiskUsageCollector:
        config:
          devices: x?vd[a-z]+[0-9]*$
      NetworkCollector: {}
      ProcessResourcesCollector:
        config:
          enabled: true
          unit: B
          measure_collector_time: true
          cpu_interval: 0.5
          process:
            hyperkube:
              name: hyperkube

  agent_config: &agent_config
    install_method: remote
    user: { get_input: agent_user }
    min_workers: 2

node_templates:

  kubernetes_master_host:
    type: cloudify.openstack.nodes.Server
    properties:
      agent_config:
        <<: *agent_config
      image: { get_input: image }
      flavor: { get_input: flavor }
    relationships:
      - target: kubernetes_security_group
        type: cloudify.openstack.server_connected_to_security_group
      - type: cloudify.openstack.server_connected_to_floating_ip
        target: kubernetes_master_ip

  kubernetes_master_ip:
    type: cloudify.openstack.nodes.FloatingIP

  kubernetes_security_group:
    type: cloudify.openstack.nodes.SecurityGroup
    properties:
      security_group:
        name: kubernetes_security_group
        description: kubernetes master security group
      rules:
      - remote_ip_prefix: 0.0.0.0/0
        port: 22
      - remote_ip_prefix: 0.0.0.0/0
        port: 53
      - remote_ip_prefix: 0.0.0.0/0
        port: 53
        protocol: udp
      - remote_ip_prefix: 0.0.0.0/0
        port: 80
      - remote_ip_prefix: 0.0.0.0/0
        port: 443
      - remote_ip_prefix: 0.0.0.0/0
        port: 2379
      - remote_ip_prefix: 0.0.0.0/0
        port: 4001
      - remote_ip_prefix: 0.0.0.0/0
        port: 6443
      - remote_ip_prefix: 0.0.0.0/0
        port: 8000
      - remote_ip_prefix: 0.0.0.0/0
        port: 8080
      - remote_ip_prefix: 0.0.0.0/0
        port: 9090
      - remote_ip_prefix: 0.0.0.0/0
        port: 10250

  kubernetes_master:
    type: cloudify.nodes.SoftwareComponent
    interfaces:
      cloudify.interfaces.lifecycle:
        start:
          implementation: fabric.fabric_plugin.tasks.run_commands
          inputs:
            fabric_env:
              host_string: { get_attribute: [ kubernetes_master_host, ip ] }
              user: { get_input: agent_user }
              key_filename: { get_input: ssh_keyfile }
            commands:
              - "curl -LO https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectl"
              - "chmod +x kubectl"
              - "sudo apt-get install -y git"
              - "rm -rf kube-deploy"
              - "git clone https://github.com/kubernetes/kube-deploy"
              - "cd kube-deploy/docker-multinode;sudo ./master.sh"
    relationships:
      - type: cloudify.relationships.contained_in
        target: kubernetes_master_host

  kubernetes_node_host:
    # A virtual machine that will get a Kubernetes node installed on it.
    type: cloudify.openstack.nodes.Server
    instances:
      deploy: 2
    properties:
      agent_config:
        <<: *agent_config
      image: {get_input: image}
      flavor: {get_input: flavor}
    relationships:
      - target: kubernetes_security_group
        type: cloudify.openstack.server_connected_to_security_group
    interfaces:
      cloudify.interfaces.monitoring_agent:
          install:
            implementation: diamond.diamond_agent.tasks.install
            inputs:
              diamond_config:
                interval: 1
          start: diamond.diamond_agent.tasks.start
          stop: diamond.diamond_agent.tasks.stop
          uninstall: diamond.diamond_agent.tasks.uninstall
      cloudify.interfaces.monitoring:
          start:
            implementation: diamond.diamond_agent.tasks.add_collectors
            inputs:
              <<: *hyperkube_monitoring

  kubernetes_node:
    type: cloudify.nodes.SoftwareComponent
    interfaces:
      cloudify.interfaces.lifecycle:
        start:
          implementation: fabric.fabric_plugin.tasks.run_commands
          inputs:
            fabric_env:
              host_string: { get_attribute: [ kubernetes_node_host, ip ] }
              user: { get_input: agent_user }
              key_filename: { get_input: ssh_keyfile }
            commands:
              - "sudo apt-get install -y git"
              - "rm -rf kube-deploy"
              - "git clone https://github.com/kubernetes/kube-deploy"
              - { concat: [ "cd kube-deploy/docker-multinode;sudo MASTER_IP=", { get_attribute: [ kubernetes_master_host, ip ] }," ./worker.sh" ] }
    relationships:
      - type: cloudify.relationships.depends_on
        target: kubernetes_master
      - type: cloudify.relationships.contained_in
        target: kubernetes_node_host


  kubectl:
    # For convenience, we install the kubectl on your master.
    type: cloudify.nodes.Root
    interfaces:
      cloudify.interfaces.lifecycle:
        create:
          implementation: scripts/kubectl.py
          inputs:
            kubectl_url: 'http://storage.googleapis.com/kubernetes-release/release/v1.0.1/bin/linux/amd64/kubectl'
    relationships:
      - type: cloudify.relationships.contained_in
        target: kubernetes_master_host
groups:

 scale_up_group:
   members: [kubernetes_node_host]
    # This defines a scale group whose members may be scaled up, incrementing by 1.
    # The scale worflow is called when the following criteria are met
    # The Hyperkube process total CPU will be more than 3 for a total of 10 seconds.
    # No more than 6 hosts will be allowed.
   policies:
     auto_scale_up:
       type: scale_policy_type
       properties:
         policy_operates_on_group: true
         scale_limit: 6
         scale_direction: '<'
         scale_threshold: 30
         #service_selector: .*kubernetes_node_host.*.cpu.total.user
         service_selector: .*kubernetes_node_host.*cpu.total.user
         cooldown_time: 60
       triggers:
         execute_scale_workflow:
           type: cloudify.policies.triggers.execute_workflow
           parameters:
             workflow: scale
             workflow_parameters:
               delta: 1
               scalable_entity_name: kubernetes_node
               scale_compute: true

 scale_down_group:
   # This defines a scale group whose members may be scaled down. Only one host will be removed per run.
   # The scale worflow is called when the following criteria are met
   # The Hyperkube process total CPU will be less than 1 for a total of 200 seconds.
   # No less than 2 hosts will be allowed.
   members: [kubernetes_node_host]
   policies:
     auto_scale_down:
       type: scale_policy_type
       properties:
         scale_limit: 2
         scale_direction: '>'
         scale_threshold: 25
         #service_selector: .*kubernetes_node_host.*.process.hyperkube.cpu.percent
         service_selector: .*kubernetes_node_host.*cpu.total.user
         cooldown_time: 60
         moving_window_size: 30
       triggers:
         execute_scale_workflow:
           type: cloudify.policies.triggers.execute_workflow
           parameters:
             workflow: scale
             workflow_parameters:
               delta: -1
               scalable_entity_name: kubernetes_node
               scale_compute: true

 heal_group:
   # This defines a group of hosts in members that may be healed.
   # The heal workflow is called when a the following policy criteria are met.
   # Either the hyperkube process on the host, or the total host CPU need fall silent.
   # The host and all software that it is supposed to have running on it will be healed.
   members: [kubernetes_node_host]
   policies:
     simple_autoheal_policy:
       type: cloudify.policies.types.host_failure
       properties:
         service:
           - .*kubernetes_node_host.*.cpu.total.system
           - .*kubernetes_node_host.*.process.hyperkube.cpu.percent
         interval_between_workflows: 60
       triggers:
         auto_heal_trigger:
           type: cloudify.policies.triggers.execute_workflow
           parameters:
             workflow: heal
             workflow_parameters:
               node_instance_id: { 'get_property': [ SELF, node_id ] }
               diagnose_value: { 'get_property': [ SELF, diagnose ] }

outputs:
  kubernetes_info:
    description: Kubernetes Dashboard URL
    value:
      url: {concat: ["http://",{ get_attribute: [ kubernetes_master_ip, floating_ip_address ]},":8080/api/v1/proxy/namespaces/kube-system/services/kubernetes-dashboard" ] }
